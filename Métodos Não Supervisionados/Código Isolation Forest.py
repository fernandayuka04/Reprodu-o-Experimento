import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# 1. GeraÃ§Ã£o de Dados
# Define a semente aleatÃ³ria para reprodutibilidade
np.random.seed(42)

# Gera 500 amostras (dados "normais") a partir de uma distribuiÃ§Ã£o normal 2D
X_normal = 0.3 * np.random.randn(500, 2)
# Desloca o centro da distribuiÃ§Ã£o para (2, 2)
X_normal = X_normal + 2

# 2. InserÃ§Ã£o de Anomalias (Outliers)
# Gera 20 anomalias bem distantes dos dados normais
n_anomalies = 20
X_anomalies = np.random.uniform(low=-4, high=4, size=(n_anomalies, 2))
X_anomalies = X_anomalies + 6 # Garante que as anomalias fiquem longe

# Combina os dados normais e as anomalias
X = np.vstack([X_normal, X_anomalies])
n_samples = len(X)

# Cria os rÃ³tulos verdadeiros: 1 para normal, -1 para anomalia
# 500 normais (1) e 20 anomalias (-1)
y_true = np.array([1] * len(X_normal) + [-1] * len(X_anomalies))

# 3. Treinamento do Modelo Isolation Forest
# O parÃ¢metro 'contamination' Ã© a fraÃ§Ã£o esperada de outliers no conjunto de dados.
contamination_rate = n_anomalies / n_samples

# n_estimators: nÃºmero de Ã¡rvores na floresta (mais Ã¡rvores geralmente melhoram a precisÃ£o)
# max_samples: nÃºmero de amostras a serem desenhadas para treinar cada Ã¡rvore
model = IsolationForest(contamination=contamination_rate, random_state=42, n_estimators=100)

# Treina o modelo (nÃ£o supervisionado, usa apenas os dados)
model.fit(X)

# 4. PrediÃ§Ã£o e AvaliaÃ§Ã£o
# A prediÃ§Ã£o retorna 1 para pontos inliers (normais) e -1 para pontos outliers (anomalias)
y_pred = model.predict(X)

# --- CORREÃ‡ÃƒO: CÃ¡lculo do Limiar de DecisÃ£o para Plotagem ---
# O limiar nÃ£o Ã© acessÃ­vel diretamente via 'threshold_'.
# Calculamos o limiar a partir dos scores da funÃ§Ã£o de decisÃ£o (decision_function)
# no conjunto de treino (X) e na taxa de contaminaÃ§Ã£o (contamination_rate).
scores = model.decision_function(X)
# O limiar Ã© o score no percentil correspondente Ã  taxa de contaminaÃ§Ã£o.
# Pontos com scores ABAIXO deste valor sÃ£o classificados como anomalias.
model_threshold = np.percentile(scores, contamination_rate * 100)
# -----------------------------------------------------------------


# 5. Resultados em NÃºmeros (MÃ©tricas de AvaliaÃ§Ã£o)
print("## ðŸ“Š Resultados em NÃºmeros")
print("-" * 30)

# Matriz de ConfusÃ£o e CÃ¡lculo de MÃ©tricas (usando o rÃ³tulo -1 como positivo para anomalia)
print(f"Total de Amostras: {n_samples}")
print(f"Anomalias Inseridas (Verdadeiras): {n_anomalies}")
print(f"Anomalias Detectadas (Preditas): {list(y_pred).count(-1)}")
print("\n--- Matriz de ConfusÃ£o ---")
print("Predito: Anomalia (-1) | Predito: Normal (1)")
# Conta True Positive e False Negative
tp = list(y_pred[y_true == -1]).count(-1)
fn = list(y_pred[y_true == -1]).count(1)
# Conta False Positive e True Negative
fp = list(y_pred[y_true == 1]).count(-1)
tn = list(y_pred[y_true == 1]).count(1)

print(f"Real: Anomalia (-1) -> | {tp:<15}| {fn:<10}")
print(f"Real: Normal (1)   -> | {fp:<15}| {tn:<10}")
print("\n--- MÃ©tricas ---")
print(f"AcurÃ¡cia: {accuracy_score(y_true, y_pred):.4f}")
print(f"PrecisÃ£o (Anomalia -1): {precision_score(y_true, y_pred, pos_label=-1):.4f}")
print(f"Recall (Anomalia -1): {recall_score(y_true, y_pred, pos_label=-1):.4f}")
print(f"F1-Score (Anomalia -1): {f1_score(y_true, y_pred, pos_label=-1):.4f}")


# 6. Resultados em GrÃ¡ficos
print("\n## ðŸ“ˆ Resultados em GrÃ¡ficos")
# Cria uma malha para desenhar o contorno de decisÃ£o
xx, yy = np.meshgrid(np.linspace(min(X[:, 0])-1, max(X[:, 0])+1, 100),
                     np.linspace(min(X[:, 1])-1, max(X[:, 1])+1, 100))

# Calcula a funÃ§Ã£o de decisÃ£o (scores) para cada ponto na malha
Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.figure(figsize=(10, 6))

# Desenha o contorno de decisÃ£o
# O valor de corte Ã© determinado pelo modelo baseado no 'contamination'
plt.contourf(xx, yy, Z, cmap=plt.cm.YlGnBu, alpha=0.3)
# Linha de fronteira (limite entre inlier e outlier) - USANDO O LIMIAR CALCULADO
plt.contour(xx, yy, Z, levels=[model_threshold], linewidths=2, colors='darkgreen')

# Plota os dados normais
plt.scatter(X_normal[:, 0], X_normal[:, 1], c='white', edgecolors='k', s=20, label='Dados Normais (Verdadeiros)')
# Plota as anomalias (verdadeiras)
plt.scatter(X_anomalies[:, 0], X_anomalies[:, 1], c='red', edgecolors='k', s=50, label='Anomalias (Verdadeiras)')

# Marca os pontos classificados como anomalia (-1)
anomalies_pred_idx = np.where(y_pred == -1)
plt.scatter(X[anomalies_pred_idx, 0], X[anomalies_pred_idx, 1], c='orange', marker='x', s=100, linewidths=2, label='Anomalias (Preditas)')

plt.title("Isolation Forest para DetecÃ§Ã£o de Anomalias")
plt.xlabel("CaracterÃ­stica 1")
plt.ylabel("CaracterÃ­stica 2")
plt.legend()
plt.show()